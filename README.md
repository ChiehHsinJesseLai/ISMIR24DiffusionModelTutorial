# From White Noise to SymphonyðŸŽ¼: Diffusion Models for Music and Sound -- ISMIR24 Diffusion Model Tutorial

Please find our [project page](https://sites.google.com/view/diffusion-tutorial-ismir24/home).

## How to cite this PDF:

```
@misc{lai24diffusionmodeltutorial,
  author = {Lai, Chieh-Hsin and Nguyen, Bac and Saito, Koichi and Ermon, Stefano and Mitsufuji, Yuki},
  title = {From White Noise to Symphony: Diffusion Models for Music and Sound -- ISMIR24 Diffusion Model Tutorial},
  year = {2024},
  journal = {GitHub repository},
  url = {https://github.com/ChiehHsinJesseLai/ismir24-diffusion-tutorial}, 
}
```

## Goal: Democratizing Diffusion Models to Music and AudioðŸŽ¼
 This tutorial covered the theory and practice of diffusion models for music and sound. We will explain the methodology, explore its history, and demonstrate music and sound-specific applications such as real-time generation and various other downstream tasks. By bridging the gap from computer vision techniques and models, we aim to spark further research interest and democratize access to diffusion models for the music and sound domains. 


The tutorial comprises four sections. 

- The first provides an overview of deep generative models and delves into the fundamentals of diffusion models. 

- The second section explores applications such as sound and music generation, as well as utilizing pre-trained models for music/sound editing and restoration. 

- In the third section, a hands-on demonstration will focus on training diffusion models and applying pre-trained models for music/sound restoration. 

- The final section outlines future research directions.


## Contact
Chieh-Hsin (Jesse) LAI: <a href="chieh-hsin.lai@sony.com">chieh-hsin.lai@sony.com</a>
